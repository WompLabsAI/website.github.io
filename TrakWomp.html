<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Trak_Womp</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="styles.css" />
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<h1 align="center">
<span class="math inline">\(TRAK_{WOMP}\)</span>: A New SOTA in Data
Attribution
</h1>
<figure>
<img src="./image.png"
style="display: block; margin: 0 auto;;width:100.0%"
alt="Figure 1: TRAK_{WOMP} achieves a new SOTA by nearly an order of magnitude. It consistently makes counterfactual predictions more accurate than TRAK with 75\% fewer reference models. Per-block projection dimension is 2048." />
<figcaption aria-hidden="true"><em>Figure 1: <span
class="math inline">\(TRAK_{WOMP}\)</span> achieves a new SOTA by nearly
an order of magnitude. It consistently makes counterfactual predictions
more accurate than <span class="math inline">\(TRAK\)</span> with <span
class="math inline">\(75\%\)</span> fewer reference models. Per-block
projection dimension is 2048.</em></figcaption>
</figure>
<p><strong>In this post we outline our method, <span
class="math inline">\(TRAK\ W_{ith}\ O_{ptimally}\ M_{odified}\
P_{rojections}\)</span>, which sets a new SOTA for predicting the
downstream effects of dataset changes!</strong></p>
<h1 id="table-of-contents">Table of Contents</h1>
<ul>
<li><a href="#warmup">Warmup</a>
<ul>
<li><a href="#the-linear-datamodeling-score-lds">The Linear Datamodeling
Score (LDS)</a></li>
<li><a href="#trak">TRAK</a></li>
<li><a href="#random-projections-and-the-jl-lemma">Random Projections
and the JL Lemma</a></li>
<li><a href="#projection-dimension-and-the-h-1-approximation">Projection
Dimension and the <span class="math inline">\(H^{-1}\)</span>
Approximation</a></li>
</ul></li>
<li><a href="#trak-with-optimally-modified-projections-womp">TRAK With
Optimally Modified Projections (WOMP)</a>
<ul>
<li><a href="#an-equivalent-definition">An Equivalent
Definition</a></li>
</ul></li>
<li><a href="#evaluating-trak_womp">Evaluating TRAK_WOMP</a>
<ul>
<li><a href="#setup">Setup</a></li>
<li><a href="#results">Results</a></li>
</ul></li>
<li><a href="#more-to-come">More To Come â€¦</a></li>
</ul>
<p>At Womp Labs, we spend all of our time thinking about the way ML
models use their training data. When a model fails, it would be great to
pinpoint the source of the problem. When you have many data sources,
youâ€™d like to know if only one of them was doing the heavy lifting.</p>
<p>Anyone training models knows there is still a fair amount of
<em>witchcraft</em> that goes into turning chunks of tokens into
sensible, useful things. Some of this is interpretable, like the fact
that coding examples help with logic and reasoning problems. Some of it,
like the fact that <a href="https://arxiv.org/pdf/2404.01099">math
examples can break safety guardrails</a>, is less so. <em>And</em> it
becomes even more complicated when you consider that these heuristics
are dependent on the model youâ€™re training and the other data at your
disposal. For these reasons, it becomes increasingly important to work
on ways to quantify what data points are actually contributing to a
training run.</p>
<p>The methods used to solve these problems fall under the umbrella of
data attribution. Fundamentally, this is a challenge of tracing model
outputs to training data, and then using this understanding to infer how
to change data to affect downstream behavior. Some background can be
found in <a
href="https://ml-data-tutorial.org/assets/DataTutorialICML2024.pdf">this
ICML tutorial</a>.</p>
<h2 id="warmup">Warmup</h2>
<h3 id="the-linear-datamodeling-score-lds">The Linear Datamodeling Score
(LDS)</h3>
<p>A core goal is to accurately predict the outcome of training on some
dataset without having to do so. To quantify how good a method is at
this, we can use the following:</p>
<p><span
class="math display">\[LDS(\tau,z):=\rho(f(z,\theta^*(D_j)):j\in[m],{g_\tau(z,D_j;D):j\in[m]})\tag{1}\]</span></p>
<p>where <span class="math inline">\(D\)</span> is the training set,
<span class="math inline">\(f\)</span> is the output of model <span
class="math inline">\(\theta^*\)</span>, trained on <span
class="math inline">\(D_j\subset D\)</span>, on an example of interest
<span class="math inline">\(z\)</span>, <span
class="math inline">\(m\)</span> is number of evaluation subsets, and
<span class="math inline">\(g_\tau\)</span> is the output prediction
made by attribution method <span class="math inline">\(\tau\)</span>. In
simpler terms, we are trying to answer the following question:</p>
<p><span class="math display">\[How\ accurately\ can\ we\ predict\
which\ dataset\ is\ better\ for\ learning\ example\ z?\]</span></p>
<h3 id="trak">TRAK</h3>
<p>Just over a year ago, a lab at MIT introduced <a
href="https://arxiv.org/abs/2303.14186">TRAK</a>, a data attribution
method orders of magnitudes more efficient than the prior <em>state of
the art</em>. Their approach casts the complex problem of attributing
influence in neural nets to the well understood setting of linear
regression. Leaving the details to their paper, the final form of their
method is as follows:</p>
<p><span class="math display">\[\tau_{TRAK}(z,S) :=
S(\frac{1}{M^2}(\sum_{m=1}^M
Q_m)*(\sum_{m=1}^M\phi_m(z)(\Phi_m^T\Phi_m)^{-1}\Phi_m^T),\hat\lambda)\tag{2}\]</span></p>
<p>where <span class="math inline">\(z\)</span> is an example of
interest, <span class="math inline">\(M\)</span> is the number of
reference models used, <span class="math inline">\(\phi\)</span> is a
random projection of <span class="math inline">\(\nabla_\theta
f(z)\)</span>, <span class="math inline">\(\Phi\)</span> is the stacked
matrix of <span class="math inline">\(\phi(x)\)</span> for all training
examples <span class="math inline">\(x\)</span>, <span
class="math inline">\(Q\)</span> is the diagonal matrix of <span
class="math inline">\(1-p_i\)</span>, and <span
class="math inline">\(S\)</span> is a soft threshold function with
threshold <span class="math inline">\(\hat\lambda\)</span>.</p>
<h3 id="random-projections-and-the-jl-lemma">Random Projections and the
JL Lemma</h3>
<p>One of the understood sources of error in the TRAK formulation is the
random projection step. However, a theoretical result from <a
href="https://stanford.edu/class/cs114/readings/JL-Johnson.pdf">Johnson
and Lindenstrauss</a>, which shows inner products are preserved with
high probability when projecting via a matrix <span
class="math inline">\(P\sim\mathcal{N}(0,1)^{p\times{k}}\)</span>, leads
to the belief that this error is small. As a result, the improvement
from ensembling <span class="math inline">\(M\)</span> different models
is attributed to the need for different training trajectories to sample
different possible loss landscapes.</p>
<p>We show that this is not entirely the case. In fact, a large portion
of the error comes from imperfections in the projection step.</p>
<h3 id="projection-dimension-and-the-h-1-approximation">Projection
Dimension and the <span class="math inline">\(H^{-1}\)</span>
Approximation</h3>
<p>To reduce this degradation in accuracy, one can increase the
projection dimension. But, the TRAK paper shows there is an optimal
projection dimension, beyond which performance starts to degrade. While
we expect higher-dimensional representations to be less lossy, the issue
comes from the inverse Hessian approximation <span
class="math inline">\((\Phi_m^T\Phi_m)^{-1}\)</span>. As dimensionality
increases, the number of spurious correlations grows. But, a small tweak
to the setup fixes this problem.</p>
<h2
id="trak-with-optimally-modified-projections-womp-_textithaha-see-what-we-did-there">TRAK
With Optimally Modified Projections (WOMP)<span class="math inline">\(\
_{\textit{haha,\ see\ what\ we\ did\ there}}\)</span></h2>
<p>We modify TRAK by decomposing the projected gradients into blocks. In
doing so, we produce what resembles multiple checkpoints from a single
backward pass. For example, one checkpoint projected to <span
class="math inline">\(d=4096\)</span> can also be treated as <span
class="math inline">\(4\)</span> different <span
class="math inline">\(d_{batch}=1024\)</span> checkpoints. The result is
the following formulation:</p>
<p><span class="math display">\[\tau_{TRAK_{WOMP}}(z,S) :=
S(\frac{1}{M^2}(\sum_{m=1}^M
Q_m)*(\sum_{m=1}^M\sum_{b=1}^B\phi_{m,b}(z)(\Phi_{m,b}^T\Phi_{m,b})^{-1}\Phi_{m,b}^T),\hat\lambda)\tag{3}\]</span></p>
<p>where <span class="math inline">\(B\)</span> is the number of blocks
we decompose the projection into and <span
class="math inline">\(\phi_{m,b}(z)\)</span> is the <span
class="math inline">\(b^{th}\)</span> block of <span
class="math inline">\(\phi_{m}(z)\)</span>.</p>
<h3 id="an-equivalent-definition">An Equivalent Definition</h3>
<p>An alternative way to frame our setup is as a block-wise
decomposition of the <span class="math inline">\(H^{-1}\)</span>
approximation. We redefine this term as:</p>
<p><span class="math display">\[\hat{H}_m^{-1} :=
diag(\Phi_{m,1}^T\Phi_{m,1},\Phi_{m,2}^T\Phi_{m,2},...,\Phi_{m,B}^T\Phi_{m,B})^{-1}\tag{4}\]</span></p>
<p>Finally, equivalent to <span class="math inline">\((3)\)</span>, we
come to the definition:</p>
<p><span class="math display">\[\tau_{TRAK_{WOMP}}(z,S) :=
S(\frac{1}{M^2}(\sum_{m=1}^M
Q_m)*(\sum_{m=1}^M\phi_{m}(z){\hat{H}_m}^{-1}\Phi_{m}^T),\hat\lambda)\tag{5}\]</span></p>
<p>Our simple change allows us to increase the projection dimension,
thereby achieving higher resolution representations, without sacrificing
the accuracy of the Hessian approximation. What is nice about this setup
is it introduces no additional backward passes per reference model.</p>
<p style="text-align: center;">
<i>This lets us make better predictions without multi-million dollar
donations to NVIDIA!</i>
</p>
<h2 id="evaluating-trak_womp">Evaluating <span
class="math inline">\(TRAK_{WOMP}\)</span></h2>
<h3 id="setup">Setup</h3>
<p>Our goal is to accurately predict the result of training a <span
class="math inline">\(Resnet-9\)</span> on a given subset of <span
class="math inline">\(CIFAR10\)</span> without having to train the
model. To make these predictions we train <span
class="math inline">\(M\)</span> models on random <span
class="math inline">\(50\%\)</span> subsets of the dataset. We use
checkpoints from these models as reference models to compute attribution
scores. We then evaluate the methods with <span
class="math inline">\(LDS\)</span> using <span
class="math inline">\(10,000\)</span> models.</p>
<h3 id="results">Results</h3>
<figure>
<img src="./performance_comparison_bar.png"
style="display: block; margin: 0 auto;;width:100.0%"
alt="Figure 2: We evaluate the most common real-world scenario: M=1 reference model. TRAK_{WOMP} results in predictions that are over 2.5\ times more accurate than TRAK." />
<figcaption aria-hidden="true"><em>Figure 2: We evaluate the most common
real-world scenario: <span class="math inline">\(M=1\)</span> reference
model. <span class="math inline">\(TRAK_{WOMP}\)</span> results in
predictions that are over <span class="math inline">\(2.5\
times\)</span> more accurate than <span
class="math inline">\(TRAK\)</span>.</em></figcaption>
</figure>
<p>In most settings it is not feasible to retrain multiple models. As a
result, the most important measure of effectiveness is the performance
when only using <span class="math inline">\(M=1\)</span> model. We show
that <span class="math inline">\(TRAK_{WOMP}\)</span> drastically
outperforms vanilla <span class="math inline">\(TRAK\)</span>.</p>
<figure>
<img src="./effect_of_blocks.png"
style="display: block; margin: 0 auto;;width:100.0%"
alt="Figure 3: We illustrate the utility of increasing the number of blocks when the projection dimension is fixed. In this case, we use d = 32768." />
<figcaption aria-hidden="true"><em>Figure 3: We illustrate the utility
of increasing the number of blocks when the projection dimension is
fixed. In this case, we use <span class="math inline">\(d =
32768\)</span>.</em></figcaption>
</figure>
<p>So far, we have shown results when per-block projection dimension was
fixed. However, we know this requires <span class="math inline">\(B\
times\)</span> more storage. In some cases there can be storage
constraints as well. In <em>Figure 3</em>, we fix the total projection
dimension, <span class="math inline">\(d\)</span>, and vary <span
class="math inline">\(B\)</span>. Our results show that not only is
<span class="math inline">\(TRAK_{WOMP}\)</span> superior on a fixed
compute budget, it is better on a fixed storage budget as well.</p>
<h2 id="more-to-come">More To Come â€¦</h2>
<p>We know these results are on a small scale model, but we have more to
share soon on billion(s) parameter models and internet scale datasets.
We believe we can eliminate the <em>hope</em> and <em>guesswork</em>
when training large models. If you agree and are interested in
collaborating or joining the team, please reach us at <a
href="mailto:contact@womplabs.ai">contact@womplabs.ai</a>! If you would
like to stay up to date on our work, <a
href="https://forms.gle/vzDzFeeW4d9jFjRJ7">sign up here</a>.</p>
<p>See you next time ðŸ™‚</p>
</body>
</html>
